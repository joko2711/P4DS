{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb2f812",
   "metadata": {},
   "source": [
    "# Project invoices\n",
    "*KUBIK Aleksander - KOBANA Johan - JOUYIT Matthieu - Thomas BOULAINE - DIA4*\n",
    "\n",
    "\n",
    "Our problem : How can we analyze and visualize an online store‚Äôs activity using an invoice dataset to extract key indicators that support data-driven decisions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": null,
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
   "id": "4ee73779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "\n",
    "from prophet import Prophet\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": null,
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
   "id": "adfa19a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Function for reading a CSV file\n",
    "    Input: the path to the CSV file (string)    \n",
    "    Output: a dataframe containing the loaded dataset\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)   # Read the CSV into a pandas DataFrame\n",
    "    return df                     # Return the full dataset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": null,
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
   "id": "776e5b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_info(data):\n",
    "    \"\"\"\n",
    "    Function to display basic information about a dataframe\n",
    "    Input: a dataframe\n",
    "    Output: printed information (shape, columns, dtypes, missing values)\n",
    "    \"\"\"\n",
    "    print(\"Shape:\", data.shape)                     # Print number of rows and columns\n",
    "    print(\"\\nColumns:\", data.columns.tolist())      # Print list of column names\n",
    "\n",
    "    print(\"\\nData types:\")                          # Print data types of each column\n",
    "    print(data.dtypes)\n",
    "\n",
    "    print(\"\\nMissing values per column:\")           # Print missing values for each column\n",
    "    print(data.isna().sum())\n",
    "\n",
    "    print(\"\\nDescriptive statistics:\")\n",
    "    categorical_cols = [\n",
    "    'first_name', 'city', 'job'\n",
    "    ]\n",
    "    for col in categorical_cols:                    #Ranking between categorical variables\n",
    "        print(f\"\\nTop 5 values for {col}:\")         #Clients plus pr√©sents, villes dominantes\n",
    "        print(data[col].value_counts().head(5))     #professions majoritaires\n",
    "\n",
    "    numeric_ranking = data[['qty', 'amount']].agg(['mean', 'sum', 'std']).T     #Ranking between numerical variables\n",
    "    numeric_ranking = numeric_ranking.sort_values(by='sum', ascending=False)    #Most influent variable economicaly and volume\n",
    "    print(numeric_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32653e96",
   "metadata": {},
   "source": [
    "### First exploration of the dataset\n",
    "\n",
    "Before jumping into analysis or modeling, it is essential to understand the structure of the data.\n",
    "\n",
    "This function provides a global overview of the dataset by:\n",
    "- Displaying its **shape** (number of rows and columns)\n",
    "- Listing all **column names**\n",
    "- Showing **data types** for each variable\n",
    "- Checking for **missing values**\n",
    "- Exploring the most frequent values for key categorical variables such as:\n",
    "  - client names\n",
    "  - cities\n",
    "  - professions\n",
    "\n",
    "It also computes basic statistics for numerical variables (`quantity` and `amount`) in order to identify which metrics have the biggest impact on the business.\n",
    "\n",
    "This step helps us detect potential data quality issues and guides the next stages of the analysis."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": null,
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
   "id": "57232911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dates(data):\n",
    "    \"\"\"\n",
    "    Function to preprocess date-related fields\n",
    "    Input: a dataframe\n",
    "    Output: the same dataframe with parsed dates, changing type and extracted year/month\n",
    "    \"\"\"\n",
    "    data[\"invoice_date\"] = pd.to_datetime(data[\"invoice_date\"], format=\"%d/%m/%Y\")  # Convert date string to datetime\n",
    "    data[\"year\"] = data[\"invoice_date\"].dt.year                                      # Extract year\n",
    "    data[\"month\"] = data[\"invoice_date\"].dt.month                                    # Extract month\n",
    "    data[\"product_id\"] = data[\"product_id\"].astype(str)                              # Ensure product_id is string\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c005510",
   "metadata": {},
   "source": [
    "Here we convert the `invoice_date` column into a real datetime format.  \n",
    "We also create two new columns: `year` and `month`.\n",
    "\n",
    "These will be useful later when we study trends in sales over time."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": null,
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
   "id": "52407e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sales_by_month(invoice):\n",
    "    \"\"\"\n",
    "    Compute total monthly revenue based on 'amount'.\n",
    "    \"\"\"\n",
    "    monthly_sales = invoice.groupby([\"year\", \"month\"])[\"amount\"].sum().reset_index()\n",
    "    monthly_sales[\"date\"] = pd.to_datetime(\n",
    "        monthly_sales[\"year\"].astype(str) + \"-\" + monthly_sales[\"month\"].astype(str) + \"-01\"\n",
    "    )\n",
    "    return monthly_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d07b2f7",
   "metadata": {},
   "source": [
    "This function calculates the total sales for each month.  \n",
    "We group the data by year and month, then sum the amounts.\n",
    "\n",
    "It gives us our first time-based indicator: how the store‚Äôs sales evolve over time."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": null,
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
   "id": "c6dd0ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_products(df, n=10):\n",
    "    \"\"\"\n",
    "    Function to compute the top-N best-selling products\n",
    "    Input: \n",
    "      df : dataframe containing at least 'product_id' and 'amount'\n",
    "      n  : number of products to return (default = 10)\n",
    "    Output: \n",
    "      a dataframe with the N products that generate the highest total amount\n",
    "    \"\"\"\n",
    "    top = (\n",
    "        df.groupby(\"product_id\")[\"amount\"]      # group by product and sum revenue\n",
    "          .sum()\n",
    "          .reset_index()                        # back to a flat dataframe\n",
    "          .sort_values(by=\"amount\", ascending=False)  # highest revenue first\n",
    "          .head(n)                              # keep only top N\n",
    "    )\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": null,
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
   "id": "08999fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_basket(invoice):\n",
    "    \"\"\"\n",
    "    Compute the average spending per customer.\n",
    "    \"\"\"\n",
    "    avg = invoice.groupby(\"email\")[\"amount\"].mean().reset_index()\n",
    "    avg.rename(columns={\"amount\": \"avg_basket\"}, inplace=True)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": null,
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
   "id": "e64259d0-1143-42d1-9676-edf9917c3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_mining_by_job(df, min_support=0.01, top_n=10):\n",
    "    \"\"\"\n",
    "    Function to extract association rules by job\n",
    "    Input:  \n",
    "      df (with columns 'job', 'product_id', 'qty')\n",
    "      min_support\n",
    "      top_n\n",
    "    Output: dataframe with the strongest association rules\n",
    "    \"\"\"\n",
    "\n",
    "    basket = df.groupby(['job', 'product_id'])['qty'].sum().unstack().fillna(0)  # job‚Äìproduct matrix\n",
    "    basket = basket > 0                                                           # convert quantities to booleans\n",
    "\n",
    "    itemsets = fpgrowth(basket, min_support=min_support, use_colnames=True)       # frequent itemsets\n",
    "    if itemsets.empty:                                                            # if nothing is frequent\n",
    "        return pd.DataFrame({\"message\": [\"No frequent itemsets found\"]})          # return message instead\n",
    "\n",
    "    rules = association_rules(itemsets, metric=\"lift\", min_threshold=0)           # generate association rules\n",
    "    if rules.empty:                                                               # if no rules are found\n",
    "        return pd.DataFrame({\"message\": [\"No association rules found\"]})          # return message instead\n",
    "\n",
    "    rules[\"score\"] = rules[\"lift\"] * rules[\"confidence\"]                          # combined score = lift √ó confidence\n",
    "    rules = rules.sort_values(by=\"score\", ascending=False).head(top_n)            # keep only top_n best rules\n",
    "\n",
    "    rules[\"antecedent_txt\"] = rules[\"antecedents\"].apply(lambda x: list(x)[0])    # convert antecedent set to text\n",
    "    rules[\"consequent_txt\"] = rules[\"consequents\"].apply(lambda x: list(x)[0])    # convert consequent set to text\n",
    "\n",
    "    def get_jobs_supporting_rule(row):                                            # helper: jobs that support a rule\n",
    "        a = row[\"antecedent_txt\"]                                                # product A (antecedent)\n",
    "        b = row[\"consequent_txt\"]                                                # product B (consequent)\n",
    "\n",
    "        jobs_A = set(df[df[\"product_id\"] == a][\"job\"])                           # jobs that bought A\n",
    "        jobs_B = set(df[df[\"product_id\"] == b][\"job\"])                           # jobs that bought B\n",
    "\n",
    "        return sorted(jobs_A.intersection(jobs_B))                               # jobs that bought both A and B\n",
    "\n",
    "    rules[\"jobs_supporting_rule\"] = rules.apply(get_jobs_supporting_rule, axis=1) # add supporting jobs to each rule\n",
    "    rules[\"num_jobs\"] = rules[\"jobs_supporting_rule\"].apply(len)\n",
    "\n",
    "    return rules[[\n",
    "        \"antecedent_txt\",                                                        # product on the left side of rule\n",
    "        \"consequent_txt\",                                                        # product on the right side of rule\n",
    "        \"confidence\",                                                            # confidence of the rule\n",
    "        \"lift\",                                                                  # lift of the rule\n",
    "        \"score\",                                                                 # combined score (lift √ó confidence)\n",
    "        \"jobs_supporting_rule\",                                                  # list of jobs supporting the rule\n",
    "        \"num_jobs\"\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": null,
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
   "id": "b1b32ffd-aa61-4787-af55-b99f9c2a42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "def spatial_analysis_by_city(\n",
    "    df,\n",
    "    city_col='city',\n",
    "    amount_col='amount',\n",
    "    geocode=False,\n",
    "    top_n=15\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform spatial analysis using city information:\n",
    "    - aggregate invoice count and total revenue per city\n",
    "    - optionally geocode only the top N cities\n",
    "    \"\"\"\n",
    "\n",
    "    # Aggregation\n",
    "    city_agg = (\n",
    "        df\n",
    "        .groupby(city_col)\n",
    "        .agg(\n",
    "            invoice_count=(city_col, 'count'),\n",
    "            total_revenue=(amount_col, 'sum')\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(by='invoice_count', ascending=False)\n",
    "    )\n",
    "\n",
    "    # Keep only top N cities (important)\n",
    "    city_agg = city_agg.head(top_n)\n",
    "\n",
    "    # Optional geocoding\n",
    "    if geocode:\n",
    "        geolocator = Nominatim(user_agent=\"spatial_analysis_tp\")\n",
    "        latitudes = []\n",
    "        longitudes = []\n",
    "\n",
    "        for city in city_agg[city_col]:\n",
    "            location = geolocator.geocode(f\"{city}, France\")\n",
    "            if location:\n",
    "                latitudes.append(location.latitude)\n",
    "                longitudes.append(location.longitude)\n",
    "            else:\n",
    "                latitudes.append(None)\n",
    "                longitudes.append(None)\n",
    "            time.sleep(1)  # respect Nominatim policy\n",
    "\n",
    "        city_agg['latitude'] = latitudes\n",
    "        city_agg['longitude'] = longitudes\n",
    "\n",
    "    return city_agg\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": null,
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
   "id": "e9b73843-5c82-46f1-90df-1c609d980d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_analysis(df, last_n_years=5, window_months=6, forecast_months=0):\n",
    "    \"\"\"\n",
    "    Function for temporal analysis + optional Prophet forecasting\n",
    "    Input:  \n",
    "      df (invoice dataset)\n",
    "      last_n_years\n",
    "      window_months\n",
    "      forecast_months\n",
    "    Output: \n",
    "      monthly_df (clean monthly series)\n",
    "      forecast_df (if enabled)\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()                                                                  # work on a local copy\n",
    "\n",
    "    max_year = df[\"invoice_date\"].dt.year.max()                                     # most recent year in dataset\n",
    "    min_year = max_year - last_n_years + 1                                          # oldest year to keep\n",
    "    df = df[df[\"invoice_date\"].dt.year >= min_year]                                 # filter selected years\n",
    "\n",
    "    monthly = (                                                                     # compute monthly revenue\n",
    "        df.groupby(df[\"invoice_date\"].dt.to_period(\"M\"))[\"amount\"]                  \n",
    "        .sum()\n",
    "        .to_timestamp()\n",
    "        .reset_index(name=\"amount\")\n",
    "        .rename(columns={\"invoice_date\": \"date\"})                                    # rename for clarity\n",
    "    )\n",
    "\n",
    "    monthly[\"trend\"] = monthly[\"amount\"].rolling(window=window_months).mean()        # rolling mean trend\n",
    "\n",
    "    if forecast_months > 0:                                                          # forecasting enabled?\n",
    "        prophet_df = monthly.rename(columns={\"date\": \"ds\", \"amount\": \"y\"})            # Prophet column format\n",
    "        model = Prophet(yearly_seasonality=True)                                      # Prophet model\n",
    "        model.fit(prophet_df[[\"ds\", \"y\"]])                                            # train model\n",
    "        future = model.make_future_dataframe(periods=forecast_months, freq=\"ME\")      # extend timeline\n",
    "        forecast = model.predict(future)                                              # generate forecast\n",
    "    else:\n",
    "        forecast = None                                                               # no forecasting\n",
    "\n",
    "    return monthly, forecast                                                        "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": null,
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
   "id": "cf5ed589-464c-4f26-b7c7-27153e8afe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main pipeline\n",
    "def main():\n",
    "\n",
    "    # --------------------------\n",
    "    # 1. Load and preprocess data\n",
    "    # --------------------------\n",
    "    invoice = load_data(\"invoices.csv\")\n",
    "    df_cities = load_data(\"CitiesofFrance-VillesdeFrance.csv\")\n",
    "\n",
    "    cities = df_cities.iloc[:, 0].dropna().unique()\n",
    "    invoice['city'] = np.random.choice(\n",
    "        cities,\n",
    "        size=len(invoice),\n",
    "        replace=True\n",
    "    )\n",
    "    \n",
    "    basic_info(invoice)\n",
    "    invoice = preprocess_dates(invoice)\n",
    "\n",
    "    # --------------------------\n",
    "    # 2. Compute core indicators\n",
    "    # --------------------------\n",
    "    monthly_sales = sales_by_month(invoice)\n",
    "    top10 = top_products(invoice)\n",
    "    avg_basket = average_basket(invoice)\n",
    "\n",
    "    # --------------------------\n",
    "    # 3. Pattern mining (job-based rules)\n",
    "    # --------------------------\n",
    "    rules = pattern_mining_by_job(invoice, min_support=0.02, top_n=10)\n",
    "\n",
    "    # --------------------------\n",
    "    # 4. Temporal analysis + Prophet forecasting\n",
    "    # --------------------------\n",
    "    monthly, forecast = temporal_analysis(\n",
    "    invoice,\n",
    "    last_n_years=10,\n",
    "    window_months=6,\n",
    "    forecast_months=12\n",
    "    )\n",
    "\n",
    "    # --------------------------\n",
    "    # 5. City spatial analysis (commercial activity)\n",
    "    # --------------------------\n",
    "    city_amount = spatial_analysis_by_city(invoice,geocode=True)\n",
    "\n",
    "    print(\"Pipeline executed successfully.\")\n",
    "\n",
    "    # Return all outputs\n",
    "    return {\n",
    "        \"invoice\": invoice,\n",
    "        \"monthly_sales\": monthly_sales,\n",
    "        \"top10\": top10,\n",
    "        \"avg_basket\": avg_basket,\n",
    "        \"rules\": rules,\n",
    "        \"monthly\": monthly,\n",
    "        \"forecast\": forecast,\n",
    "        \"city_amount\" : city_amount\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": null,
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
   "id": "6ed65119",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10000, 11)\n",
      "\n",
      "Columns: ['first_name', 'last_name', 'email', 'product_id', 'qty', 'amount', 'invoice_date', 'address', 'city', 'stock_code', 'job']\n",
      "\n",
      "Data types:\n",
      "first_name       object\n",
      "last_name        object\n",
      "email            object\n",
      "product_id        int64\n",
      "qty               int64\n",
      "amount          float64\n",
      "invoice_date     object\n",
      "address          object\n",
      "city             object\n",
      "stock_code        int64\n",
      "job              object\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      "first_name      0\n",
      "last_name       0\n",
      "email           0\n",
      "product_id      0\n",
      "qty             0\n",
      "amount          0\n",
      "invoice_date    0\n",
      "address         0\n",
      "city            0\n",
      "stock_code      0\n",
      "job             0\n",
      "dtype: int64\n",
      "\n",
      "Descriptive statistics:\n",
      "\n",
      "Top 5 values for first_name:\n",
      "first_name\n",
      "David Williams        6\n",
      "Daniel Johnson        5\n",
      "Melissa Johnson       5\n",
      "Michael Brown         5\n",
      "Christopher Garcia    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 5 values for city:\n",
      "city\n",
      "Wassy                4\n",
      "Laneuvelotte         4\n",
      "Lapouyade            4\n",
      "Tr√©meheuc            4\n",
      "Bouret-sur-Canche    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 5 values for job:\n",
      "job\n",
      "Research scientist (life sciences)    29\n",
      "Agricultural consultant               28\n",
      "Engineer, manufacturing               28\n",
      "Producer, radio                       27\n",
      "Heritage manager                      26\n",
      "Name: count, dtype: int64\n",
      "             mean        sum        std\n",
      "amount  52.918236  529182.36  27.434579\n",
      "qty      5.005900   50059.00   2.576767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:28:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:28:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline executed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleksander\\AppData\\Local\\Temp\\ipykernel_23696\\104563914.py:87: DeprecationWarning:\n",
      "\n",
      "*scatter_mapbox* is deprecated! Use *scatter_map* instead. Learn more at: https://plotly.com/python/mapbox-to-maplibre/\n",
      "\n",
      "c:\\Users\\Aleksander\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\plotly\\express\\_core.py:2530: DeprecationWarning:\n",
      "\n",
      "*scattermapbox* is deprecated! Use *scattermap* instead. Learn more at: https://plotly.com/python/mapbox-to-maplibre/\n",
      "\n",
      "c:\\Users\\Aleksander\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\_plotly_utils\\basevalidators.py:2626: DeprecationWarning:\n",
      "\n",
      "*scattermapbox* is deprecated! Use *scattermap* instead. Learn more at: https://plotly.com/python/mapbox-to-maplibre/\n",
      "\n",
      "c:\\Users\\Aleksander\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\plotly\\express\\_core.py:2557: DeprecationWarning:\n",
      "\n",
      "*scattermapbox* is deprecated! Use *scattermap* instead. Learn more at: https://plotly.com/python/mapbox-to-maplibre/\n",
      "\n",
      "c:\\Users\\Aleksander\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\_plotly_utils\\basevalidators.py:2626: DeprecationWarning:\n",
      "\n",
      "*scattermapbox* is deprecated! Use *scattermap* instead. Learn more at: https://plotly.com/python/mapbox-to-maplibre/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x17164dc4050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
=======
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dash'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdash\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dash, dcc, html, dash_table\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdash_bootstrap_components\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdbc\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpx\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dash'"
     ]
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
    }
   ],
   "source": [
    "from dash import Dash, dcc, html, dash_table\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "\n",
    "#Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    data = main()\n",
    "\n",
    "# --------- Run your pipeline ---------\n",
    "top10 = data[\"top10\"]\n",
    "rules = data[\"rules\"]\n",
    "monthly = data[\"monthly\"]\n",
    "forecast = data[\"forecast\"]\n",
    "city = data[\"city_amount\"]\n",
    "\n",
    "# ============================================\n",
    "# 1. FIGURE Top 10 Products\n",
    "# ============================================\n",
    "fig_top10 = px.bar(\n",
    "    top10,\n",
    "    x=\"product_id\",\n",
    "    y=\"amount\",\n",
    "    title=\"Top 10 Products\"\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 2. FIGURE Pattern Mining Rules\n",
    "# ============================================\n",
    "fig_rules = px.scatter(\n",
    "    rules,\n",
    "    x=\"confidence\",\n",
    "    y=\"lift\",\n",
    "    size=\"score\",\n",
    "    color=\"consequent_txt\",\n",
    "    hover_name=\"antecedent_txt\",\n",
    "    hover_data=[\"num_jobs\"],\n",
    "    title=\"Association Rules (Products Bought Together)\"\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 3. FIGURE Temporal Analysis (monthly + trend + forecast)\n",
    "# ============================================\n",
    "\n",
    "fig_temp = px.line(\n",
    "    monthly,\n",
    "    x=\"date\",\n",
    "    y=\"amount\",\n",
    "    title=\"Monthly Sales (Last 10 Years)\"\n",
    ")\n",
    "fig_temp.data[0].name = \"Monthly Sales\"\n",
    "fig_temp.data[0].showlegend = True\n",
    "\n",
    "# Add trend line\n",
    "fig_temp.add_scatter(\n",
    "    x=monthly[\"date\"],\n",
    "    y=monthly[\"trend\"],\n",
    "    mode=\"lines\",\n",
    "    name=\"Trend (Rolling Mean)\",\n",
    "    line=dict(color=\"orange\", width=3)\n",
    ")\n",
    "\n",
    "# Add forecast\n",
    "if forecast is not None:\n",
    "    fig_temp.add_scatter(\n",
    "        x=forecast[\"ds\"],\n",
    "        y=forecast[\"yhat\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Forecast\",\n",
    "        line=dict(color=\"green\", width=2)\n",
    "    )\n",
    "    future = forecast[forecast[\"ds\"] > monthly[\"date\"].max()]\n",
    "\n",
    "    fig_temp.add_scatter(\n",
    "        x=list(future[\"ds\"]) + list(future[\"ds\"][::-1]),\n",
    "        y=list(future[\"yhat_upper\"]) + list(future[\"yhat_lower\"][::-1]),\n",
    "        fill=\"toself\",\n",
    "        fillcolor=\"rgba(0, 128, 0, 0.15)\",\n",
    "        line=dict(color=\"rgba(0,0,0,0)\"),\n",
    "        hoverinfo=\"skip\",\n",
    "        name=\"Confidence Interval\"\n",
    "    )\n",
    "\n",
    "# ============================================\n",
    "# 4. FIGURE City Clustering\n",
    "# ============================================\n",
    "\n",
    "fig_city = px.scatter_mapbox(\n",
    "    city.head(10),\n",
    "    lat='latitude',\n",
    "    lon='longitude',\n",
    "    size='invoice_count',          # taille des cercles\n",
    "    color='total_revenue',         # couleur = revenu\n",
    "    hover_name='city',\n",
    "    size_max=20,\n",
    "    zoom=5,\n",
    "    title='Spatial Distribution of Invoice Activity by City',\n",
    "    labels={\n",
    "        'invoice_count': 'Number of Invoices',\n",
    "        'total_revenue': 'Total Revenue'\n",
    "    }\n",
    ")\n",
    "\n",
    "fig_city.update_layout(\n",
    "    mapbox_style='carto-positron',\n",
    "    margin=dict(r=0, t=40, l=0, b=0)\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# DASH APP LAYOUT\n",
    "# ============================================\n",
    "\n",
    "app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "app.layout = html.Div([\n",
    "    \n",
    "    html.H1(\"Invoices Dashboard\", style={\"textAlign\": \"center\"}),\n",
    "\n",
    "    html.H2(\"Top 10 Products\"),\n",
    "    dcc.Graph(figure=fig_top10),\n",
    "\n",
    "    html.H2(\"Pattern Mining (Job-Based Rules)\"),\n",
    "    dcc.Graph(figure=fig_rules),\n",
    "\n",
    "    html.H2(\"Temporal Analysis (Monthly + Trend + Forecast)\"),\n",
    "    dcc.Graph(figure=fig_temp),\n",
    "\n",
    "    html.H2(\"City Clustering (Commercial Activity)\"),\n",
    "    dcc.Graph(figure=fig_city)\n",
    "])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a6d5fd",
   "metadata": {},
   "source": [
    "## üìä Explanation of 4 Key Indicators\n",
    "\n",
    "### 1Ô∏è‚É£ **Top 10 Products** (Bar Chart - Blue)\n",
    "**What is it?**  \n",
    "The 10 products that generate the **highest revenue** for the store.\n",
    "\n",
    "**Concrete Interpretation:**\n",
    "- **Product 164** is the champion (~7000‚Ç¨) ‚Üí our best-seller\n",
    "- The 10 products are relatively balanced between 6000-7000‚Ç¨\n",
    "- **Action**: Maintain sufficient stock on these 10 products\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ **Pattern Mining - Association Rules** (Scatter Plot - Colors)\n",
    "**What is it?**  \n",
    "The **pairs of products bought together** by customers in the same profession.\n",
    "\n",
    "**Graph Axes**:\n",
    "- **Confidence (X-axis)**: Probability that if customer buys A, they also buy B (27%-31%)\n",
    "- **Lift (Y-axis)**: How many times more likely than random (1.7x to 2.0x)\n",
    "- **Point Size**: Combined rule strength (score = lift √ó confidence)\n",
    "- **Color**: Consequent product (product B purchased second)\n",
    "\n",
    "**Concrete Interpretation**:\n",
    "- Point in **top-right** = best rule (high confidence and lift)\n",
    "- **Example**: If a customer buys Product 189, there's a 30% chance they'll also buy Product X\n",
    "- **Action**: Propose these pairs as bundles or promotions\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ **Temporal Analysis** (Line Chart - Blue/Orange/Green)\n",
    "**What is it?**  \n",
    "The **sales evolution** over 10 years + future predictions.\n",
    "\n",
    "**3 Curves**:\n",
    "1. **Blue** (Monthly Sales): Actual monthly sales (noisy, volatile)\n",
    "2. **Orange** (Trend): Smooth trend (6-month rolling average) ‚Üí stable general direction\n",
    "3. **Green** (Forecast): Prophet predictions for next 12 months\n",
    "4. **Green Zone**: Confidence interval (95%) ‚Üí uncertainty increases with time\n",
    "\n",
    "**Concrete Interpretation**:\n",
    "- Stable trend ‚Üí no major growth/decline\n",
    "- Confidence zone widens towards future (uncertainty increases)\n",
    "- **Action**: Plan 12 months of inventory based on Trend\n",
    "\n",
    "---\n",
    "\n",
    "### 4Ô∏è‚É£ **City Clustering - Spatial Distribution** (Map)\n",
    "**What is it?**  \n",
    "The **location of cities** based on their commercial activity.\n",
    "\n",
    "**Map Elements**:\n",
    "- **Position**: True geographic location (latitude/longitude)\n",
    "- **Circle Size**: Number of invoices per city (larger = more purchases)\n",
    "- **Color**: Total revenue generated (yellow = richer, blue = less)\n",
    "\n",
    "**Concrete Interpretation**:\n",
    "- **Large yellow circles**: VIP cities (many purchases + high amounts)\n",
    "- **Blue circles**: Emerging or niche cities\n",
    "- **Action**: Invest in logistics for major cities (Paris, Lyon)\n",
    "\n",
    "---\n",
    "\n",
    "### üìå **Summary - What decisions should we take?**\n",
    "\n",
    "| Indicator | Commercial Decision |\n",
    "|-----------|---------------------|\n",
    "| **Top 10 products** | Stock management, marketing campaigns |\n",
    "| **Association Rules** | Bundles, cross-selling strategies |\n",
    "| **Temporal Analysis** | Budget planning, annual forecasts |\n",
    "| **City Clustering** | Distribution, logistics infrastructure |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.13.4"
=======
   "version": "3.11.14"
>>>>>>> e579dfd77d04f0e1f875d021be1c10e515da94ad
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
